# ðŸ§  Offline AI Chat & Coding GUI (Rakyat Edition)
Offline AI Chat & Coding GUI dan WebUI ringan untuk menjalankan AI chat &amp; coding dengan model GGUF lokal (Offline AI Chat & Coding GUI and WebUI to run Offline AI Chat and Coding)

Moto:
GUI Rakyat Edition: Ringan, Garang, Tak Terbendung, AI GUI Bebas Crashâ„¢, Anti-Bluescreen Framework, The GUI That Refused to Die

ðŸš€ Cloned already? Donâ€™t forget to â­ if this project made your CPU smile ðŸ˜„  "ðŸ§ª Verified Stress Test Logs (Real-World AI Usage by Rakyat CPU)" ðŸ† "LLaMA.CPP Rakyat Edition: ChatGPT Experience in kilobytes." ðŸ† "Your Own GPT Pro: Local, Open-Source & Fully Customizable" ðŸ’» "Stress-Tested Terminator AI GUI" ðŸš§ "Born in CPU Hell, Forged by Low-End Desperation" ðŸŽ® "I just wanted to pirate a game..." âš™ï¸ "...but accidentally created a multiversally-compatible AI GUI." "This repo is so stable, even bugs are afraid to appear." ðŸžðŸ’€ *Powered by Bugs, Sustained by Chaos*

-------------------------------------------

ðŸ‡®ðŸ‡© This project is primarily documented in Indonesian. ðŸ‡¬ðŸ‡§ English overview is provided below. â€œThis project is based on the original LLaMA GUI by Satria Novian

-------------------------------------------

ðŸš¨ PROYEK INI SUDAH TIDAK GRATIS ðŸš¨

GUI AI Chatbot & Multichat sekarang hanya tersedia versi **berbayar murah meriah**  
âž¡ï¸ **Sekali beli, tanpa perpanjangan license.** 

Dapatkan di sini ðŸ‘‰ [Kilashare](https://kilashare.blogspot.com/)

ðŸ’– **Kenapa Berbayar?**  
Proyek ini butuh biaya untuk tetap berjalan. Kalau kamu suka dengan GUI ini dan ingin support pengembangannya, silakan beli lisensinya.

"Source code ini bukan versi final, compile ke EXE butuh setup khusus & modular stress test. Versi EXE hanya tersedia lewat pembelian resmi."

â€œBikin EXE sendiri butuh setup environment, debug modular, dan stress test berjam-jam. Dengan harga cuma sekali bayar (setara 1x nongkrong), kamu langsung dapat versi stabil siap pakai.â€

â€œVersi EXE sudah dites semua fitur aktif â†’ Chunk Resume, Auto Save, Role Mode, Stop Prompt. Fitur ini tidak aktif penuh kalau hanya pakai source code.â€

ðŸ‘‰ â€œKalian cloning repo sekali, compile sekali, error sekali. Saya compile + stress test 3 layer (py, compile, exe), hasilnya produk anti-crash. Bayar murah aja dapet yang udah siap pakai, hemat waktu debugging berminggu-minggu.â€

ðŸ“œ Chaos Dev Stress Test Protocolâ„¢
Setiap EXE lulus uji 3 lapis stress test sebelum dilepas:

ðŸ§ª Python Script Stress Test â†’ spam input, test memory leak, dan handling teks panjang.

ðŸ§ª Compile Stress Test â†’ build .exe berulang kali pakai setup modular â†’ cek crash/bug tersembunyi.

ðŸ§ª Exe Runtime Stress Test â†’ dijalankan di PC low-end sampai high-end â†’ spam fitur (resume, role, autosave, stop).

âš”ï¸ Hasil:

Anti-Crashâ„¢ Certified

Kompatibel universal dengan semua build llama-server.exe

Stable Mode (fitur aktif penuh hanya di versi EXE resmi)

ðŸ™ Terima kasih sudah mendukung chaos developer!  

## ðŸ’– Dukung Proyek Ini

Jika kamu merasa proyek ini bermanfaat dan ingin mendukung pengembangannya, kamu bisa berdonasi melalui:
ðŸ‘‰ Untuk mendapatkan source code & file GUI:

- ðŸ’¸ [Saweria](https://saweria.co/satrianovian20)
- â˜• [PayPal](https://www.paypal.com/paypalme/satrianovian)


**Bayar dulu, baru dapat akses download**
Terima kasih banyak atas dukungannya! ðŸ™

-------------------------------------------

ðŸš¨ THIS PROJECT IS NO LONGER FREE ðŸš¨

The AI Chatbot & Multichat GUI is now available only in a **cheap paid version**
âž¡ï¸ **One-time purchase, no license renewals.**

Get it here ðŸ‘‰ [Kilashare](https://kilashare.blogspot.com/)

ðŸ’– **Why Paid?**  
This project needs support to keep development going. If you find it useful, please consider supporting by purchasing a license.

"This source code is not the final version, compiling to EXE requires special setup & modular stress testing. The EXE version is only available through official purchase."

"Creating your own EXE requires hours of environment setup, modular debugging, and stress testing. For just one time buy (the equivalent of one visit), you get a ready-to-use, stable version."

"The EXE version has been tested with all active features â†’ Chunk Resume, Auto Save, Role Mode, Stop Prompt. These features are not fully active if you only use the source code."

ðŸ‘‰ â€œYou clone the repo once, compile once, and crash once. I compiled and stress-tested 3 layers (py, compile, exe), resulting in a crash-proof product. Pay less and get a ready-to-use product, saving you weeks of debugging time.â€

ðŸ“œ Chaos Dev Stress Test Protocolâ„¢
Every EXE passes a three-layer stress test before release:

ðŸ§ª Python Script Stress Test â†’ input spam, memory leak test, and long text handling.

ðŸ§ª Compile Stress Test â†’ build the .exe repeatedly using a modular setup â†’ check for hidden crashes/bugs.

ðŸ§ª Exe Runtime Stress Test â†’ run on low-end to high-end PCs â†’ feature spam (resume, role, autosave, stop).

âš”ï¸ Results:

Anti-Crashâ„¢ Certified

Universally compatible with all llama-server.exe builds

Stable Mode (full features enabled only in the official EXE version)

ðŸ™ Thank you for supporting chaos developers!  

ðŸ’– Support This Project
If this project helped you and you'd like to support its development, you can donate via:
ðŸ‘‰ To get the source code, you can donate via:

- ðŸ’¸ [Saweria](https://saweria.co/satrianovian20)
- â˜• [PayPal](https://www.paypal.com/paypalme/satrianovian)

**Pay first, then receive download access**
Thank you so much for your support! ðŸ™

-------------------------------------------

# ðŸ“Œ Model yang sudah diuji / Tested Model GGUF

| No | Nama Model GGUF                                | Ukuran Quant | RAM yang Digunakan         | OS & Kondisi Tambahan                                    | Status GUI            |
|----|------------------------------------------------|--------------|----------------------------|---------------------------------------------------------|-----------------------|
| 1  | luna-ai-llama2-uncensored.Q4_0.gguf            | Q4_0         | Â±11.6 GB of 16GB           | Windows 11 pro 24H2 + Office 2024 + music & anime video | Stable & Smooth       |
| 2  | Meta-Llama-3-8B-Instruct.Q8_0.gguf             | Q8_0         | Â±10.8 GB of 16GB           | Windows 11 pro 24H2 + Office 2024 + music & anime video | Stable & Smooth       |
| 3  | WizardLM-13B-Uncensored.Q5_K_M.gguf            | Q5_K_M       | 12.6 GB of 16 GB           | Windows 11 pro 24H2 + Office 2024                       | Tested + Stable & Smooth |
| 4  | wizardcoder-python-13b-v1.0.Q5_K_M.gguf        | Q5_K_M       | 12.6 GB of 16 GB           | Windows 11 pro 24H2 + Office 2024                       | Tested + Stable & Smooth |
| 5  | All 7B                                         | Q4_K_M       | â‰¤11.5 GB of 16GB           | Windows 11 pro 24H2 + Office 2024 + Chrome + music video 720p | Stable & Smooth  |
| 6  | All 13B (Kecuali Yi 13B)                       | Q4_K_M       | â‰¤15.5 GB of 16GB           | Windows 11 pro 24H2 + Office 2024 + Chrome + music video 720p | Stable & Smooth  |
| 7  | deepseek-coder-7b-instruct-v1.5-Q8_0.gguf      | Q8_0         | 10.8 GB of 16GB            | Windows 11 pro 24H2 + Office 2024                       | Stable & Smooth       |
| 8  | deepseek-coder-1.3b-instruct.Q4_0.gguf         | Q4_0         | 4 GB of 16GB               | Windows 11 pro 24H2 + Office 2024                       | Stable & Smooth       |
| 9  | codellama-13b.Q6_K.gguf                        | Q6_K         | â‰¤15.4 GB of 16GB           | Windows 11 pro 24H2 + Office 2024 + Chrome + Notepad++  | Stable & Smooth       |
| 10 | starcoder2-15b-Q5_K_M (1).gguf                 | Q5_K_M       | â‰¤15.5 GB of 16GB           | Windows 11 pro 24H2 + Office 2024 + Chrome + Notepad++  | Stable & Smooth       |
| 11 | DeepSeek-Coder-V2-Lite-Instruct-Q5_K_M.gguf    | Q5_K_M       | â‰¤15.5 GB of 16GB           | Windows 11 pro 24H2 + Office 2024 + Chrome + Notepad++  | Stable & Smooth       |
| 12 | Llama-3-16B.Q5_K_M.gguf                        | Q5_K_M       | â‰¤15.5 GB of 16GB           | Windows 11 pro 24H2 + Office 2024 + Chrome + Notepad++  | Stable & Smooth       |
| 13 | orcamaidxl-17b-32k.Q5_K_M.gguf                 | Q5_K_M       | â‰¤15.5 GB of 16GB           | Windows 11 pro 24H2 + Office 2024 + Chrome              | Stable & Smooth       |
| 14 | llava-v1.5-13b-Q8_0.gguf + mmproj                       | Q8_0         | â‰¤15.5 GB of 16GB           | Windows 11 pro 24H2 + Office 2024 + Chrome + Notepad + Notepad++ | Stable & Smooth |
| 15 | InternVL3-8B-Instruct-UD-Q8_K_XL.gguf          | Q8_K_XL      | â‰¤14.2 GB of 16GB           | Windows 11 pro 24H2 + Office 2024 + Chrome + Notepad + Notepad++ | Stable & Smooth |
| 16 | InternVL3-14B-Instruct-Q6_K_XL.gguf               | Q6_K_XL         | â‰¤15.5 GB of 16GB           | Windows 11 pro 24H2 + Office 2024 + Chrome + Notepad + Notepad++ | Stable & Smooth |
| 17 | mradermacher-InternVL3.5-14BQ6_K.gguf + mmproj               | Q6_K         | â‰¤15.5 GB of 16GB           | Windows 11 pro 24H2 + Office 2024 + Chrome + Notepad + Sublime text | Stable & Smooth |
| 18 | mradermacher-InternVL3_5-8BQ8_0.gguf + mmproj               | Q8_0         | â‰¤14.5 GB of 16GB           | Windows 11 pro 24H2 + Office 2024 + Chrome + Notepad + Sublime text | Stable & Smooth |
| 19 | Mistral-Small-3.2-24B-Instruct-2506-UD-Q4_K_XL.gguf + mmproj               | Q4_K_XL         | â‰¤15.7 GB of 16GB           | Windows 11 pro 24H2 + Office 2024 + Chrome + Notepad + Sublime text | Stable & Smooth |

-------------------------------------------

# Portfolio Offline AI Chat Coding GUI & WebUI Showcase (production ready version)
# ðŸ“¸ Screenshot:
ChatCPP Llama MultiCode Editor (Tkinter Edition)
![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-11-02%20200853.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-11-04%20112206.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-11-04%20111954.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-11-04%20112009.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-11-04%20112042.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-11-04%20111937.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-11-04%20112127.png)

ChatCPP LlamArgos Tkinter GUI
![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-13%20212732.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-13%20212742.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-14%20173116.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-13%20212807.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-14%20173126.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-13%20212827.png)

ChatCPP LlamArgos Ttkbootstrap GUI
![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-14%20191803.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-14%20191815.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-14%20191837.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-14%20192435.png)

ChatCPP Ttkbootstrap Multichat AI GUI - Multitab
![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-21%20110556.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-21%20192952.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-24%20114600.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-18%20174704.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-18%20174757.png)

ChatCPP Tkinter SIngle Chat AI GUI

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-03%20152033.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-03%20152045.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-03%20152108.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-03%20152120.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-03%20152500.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-03%20152616.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-03%20152647.png)

ChatCPP Phask (Flask + Php) Multichat AI WebUI

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-25%20085225.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-25%20085236.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-25%20085250.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-25%20085308.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-25%20085454.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-25%20085515.png)

ChatCPP Phask (Flask + Php) Chatbot Single Tab AI WebUI

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-26%20114537.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-26%20114603.png)

ChatCPP Tkinter Multichat AI GUI (Multimodal Custom)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-16%20193110.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-16%20193118.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-21%20211333.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-21%20212238.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-03%20151451.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-03%20151508.png)

ChatCPP GradioWeb (Gradio) Multichat AI WebUI

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-26%20100454.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-26%20100454.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-26%20100510.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-26%20100531.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-26%20100546.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-26%20100605.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-26%20100620.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-26%20100643.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-26%20101208.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-26%20101247.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-26%20101333.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-26%20101345.png)

ChatCPP Tkinter Multichat AI GUI

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-08-30%20195558.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-08-30%20195609.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-03%20151022.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-03%20151053.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-03%20151104.png)

ChatCPP TkinterWeb Multisession AI GUI

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-18%20175405.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-16%20202758.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-18%20175507.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-18%20175526.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-18%20175542.png)

ChatCPP TkinterWeb Multitab + Multisession AI GUI - Ttkbootstrap

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-18%20181806.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-18%20181820.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-18%20181843.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-18%20181913.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-18%20182010.png)

ChatCPP Multichat (Multitab + Multisession) TkBootstrapWeb - tkinter + ttkbootstrap + tkinterweb

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-18%20182818.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-18%20182830.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-18%20182853.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-18%20182912.png)

![Screenshot](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-18%20182935.png)

# ðŸŽ¥ Video :
ChatCPP Ttkbootstrap Multichat AI GUI Demo
[![Watch the demo](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-21%20110556.png)](https://www.youtube.com/watch?v=szpQFl2sN1U)

ChatCPP GradioWeb (Gradio) Multichat AI WebUI Demo
[![Watch the demo](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-09-26%20100454.png)](https://www.youtube.com/watch?v=2offZ1urkCo)

ChatCPP Tkinter Multisession AI GUI Demo
[![Watch the demo](https://github.com/satrianovian20/Offline-ai-chat-coding-gui/blob/main/doc/Screenshot%202025-10-11%20150826.png)](https://www.youtube.com/watch?v=rZHz-49WmeI) 

---

## ðŸ‡®ðŸ‡© **Versi Bahasa Indonesia**

# ðŸ§  offline-ai-chat-coding-gui (Change Log)

## CHANGELOG RETRO CHAOS DEVELOPER EDITION

### Added

ðŸ–¼ï¸ Cek screenshot di repo, semua fitur baru kelihatan kok ðŸ˜Ž

### Fixed

ðŸž Bug fix? Pasti dong. Kayak biasa, tiap update makin cepat & stabil ðŸ’ª
(Gak percaya? Jalankan aja, kalau gak error berarti udah fix ðŸ˜Ž)

### Changed

âš™ï¸ Tambah fitur baru sambil nambal bug di fitur barunya.
Jangan tanya lagi ada bug atau enggak â€” ini gaya klasik Retro Developer ðŸ¤£

---

## ðŸ‡¬ðŸ‡§ **English Version**

# ðŸ§  offline-ai-chat-coding-gui (Change Log)

## CHANGELOG RETRO CHAOS DEVELOPER EDITION

### Added

ðŸ–¼ï¸ Check the screenshots in the repo â€” all new features are clearly visible ðŸ˜Ž

### Fixed

ðŸž Bug fixes? Of course! As always, every update runs faster and smoother ðŸ’ª
(Donâ€™t believe it? Just run it â€” if it doesnâ€™t crash, itâ€™s fixed ðŸ˜Ž)

### Changed

âš™ï¸ Added new features while patching the new featureâ€™s own bugs.
Donâ€™t even ask if there are more bugs â€” this is the classic Retro Developer style ðŸ¤£

---

ðŸ‡®ðŸ‡© Bahasa Indonesia:
âœ… FAQ â€” Pertanyaan Umum (Trust Booster Edition) 

â“ GUI ini beneran bisa jalanin model 13B tanpa GPU? Ya! Sudah diuji langsung dengan model llama-2-13b-chat.Q4_K_M.gguf di sistem dengan:

ðŸ’» CPU: Intel i5-9400F (tanpa iGPU)

ðŸ§  RAM: 16GB DDR4

âš™ï¸ Backend: llama.cpp

ðŸ“¦ GUI: Llamacpp AI Chatbot GUI

â“ Bukti nyatanya mana? ðŸ“¸ Screenshot saat load model dan idle sudah diunggah di folder docs/screenshots/

ðŸ“„ Log lengkap sesi percobaan model 13B tersedia di docs/session-logs/

Tidak ada error, tidak crash, hanya delay wajar saat proses berat.

â“ GUI-nya berat gak? Tidak. GUI ini hanya 10KB, tanpa dependensi besar seperti Gradio atau Electron.

Tidak buka port aneh-aneh.

Tidak ada tracking.

Murni offline dan lokal.

UI sangat ringan, hanya berbasis tkinter.

â“ Bisa pakai model 7B, 8B, atau 13B lain? Bisa! Sudah diuji dengan:

Mistral 7B

DeepSeek Coder 6.7B

DeepSeek Coder 7B

Nous Hermes 13B (Q4_K_M)

LLaMA 13B (Q4_K_M)

â“ RAM saya cuma 8GB, bisa jalan? Bisa, asal model yang dipilih sesuai. Gunakan model kecil seperti:

TinyLlama 1.1B Q8_0

DeepSeek Coder 1.3b Q8_0

Mistral 4B Q8_0

Open Hermes 7B Q4_K_M

Atur max_tokens di GUI agar tidak melebihi kapasitas RAM kamu.

â“â€œSaya masih nggak percaya GUI ini bisa jalanin model 13B cuma dengan RAM 16GB. Beneran bisa?â€ ðŸ’¬ â€œCoba sendiri aja bro ðŸ˜Žâ€

â“â€œEmang GUI-nya ringan banget ya?â€ âœ… Iya. Ukuran file .py cuma mb. Gak ada embel-embel web server, backend rumit, atau library berat.

â“â€œBisa crash gak pas load model besar?â€ ðŸš« Selama sistem kamu stabil dan swap file aktif, hampir nggak pernah crash. Bahkan log menunjukkan performa tetap normal walau RAM di atas 15GB pas awal load.

â“â€œAda buktinya?â€ ðŸ“¸ Sudah ada screenshot dan log di folder docs/session-logs/ dan docs/screenshots/.

â“â€œKalau saya nggak percaya tetap?â€ ðŸ˜Ž Silakan buktikan sendiri.


ðŸ‡¬ðŸ‡§ English Version:

âœ… FAQ â€” Frequently Asked Questions (Trust Booster Edition) 

â“ Can this GUI really run a 13B model without a GPU? âœ… Yes! Successfully tested with llama-2-13b-chat.Q4_K_M.gguf on:

ðŸ’» CPU: Intel i5-9400F (no iGPU)

ðŸ§  RAM: 16GB DDR4

âš™ï¸ Backend: llama.cpp

ðŸ“¦ GUI: Llamacpp AI Chatbot GUI

â“ Whereâ€™s the real proof? ðŸ“¸ Screenshots during model load and idle are uploaded to docs/screenshots/ ðŸ“„ Complete 13B model session logs available in docs/session-logs/ âœ… No errors, no crashes. Just slight delay under heavy processing â€” perfectly normal.

â“ Is this GUI heavy? âŒ Not at all. Itâ€™s just 10KB. No bloated dependencies like Gradio or Electron. âœ”ï¸ No random ports. No tracking. âœ”ï¸ 100% offline and local. âœ”ï¸ Based purely on Tkinter.

â“ Can I use other 7B, 8B, or 13B models? âœ… Absolutely! Already tested with:

Mistral 7B

DeepSeek Coder 6.7B

DeepSeek Coder 7B

Nous Hermes 13B (Q4_K_M)

LLaMA 13B (Q4_K_M)

â“ I only have 8GB RAM, will it work? âœ… Yes, just use smaller models like:

TinyLlama 1.1B Q8_0

DeepSeek Coder 1.3b Q8_0

Mistral 4B Q8_0

Open Hermes 7B Q4_K_M

ðŸ› ï¸ Set max_tokens low to match your available RAM in the GUI settings.

â“ â€œI still donâ€™t believe this GUI can run 13B on just 16GB RAM. Really?â€ ðŸ’¬ â€œTry it yourself, bro. ðŸ˜Žâ€

â“ â€œIs the GUI really that lightweight?â€ âœ… Yep. File size is only mb. No web servers, no complex backends, no heavy libraries.

â“ â€œWill it crash when loading large models?â€ ðŸš« As long as your system is stable and swap file is active, crashes are extremely rare. ðŸ“Š Even with RAM above 15GB during model load, logs show stable performance.  

â“ â€œIs there actual proof?â€ ðŸ“¸ Yes. Screenshots and logs are available in the docs/session-logs/ and docs/screenshots/ folders.

â“ â€œWhat if I still donâ€™t believe?â€ ðŸ˜Ž Feel free to test it yourself. 

----------------------

# ðŸ’¡ Catatan:  
> Repo ini hanya berisi **kode eksperimen Tkinter**.  
> Versi **production-ready** (Tkinter Pro, TTKBootstrap mirip ChatGPT, Gradio WebUI, Flask+PHP Multitab) **tidak dipublikasikan di sini**.  
> Screenshot & video demo di repo menunjukkan fitur lengkap dari berbagai versi yang sudah production ready.

----------------------

## ðŸ’¡ About This Project
This repository contains **experimental open-source code** for the multi-tab AI Chatbot GUI,  
along with a **fully working .exe demo** for public showcase.

> âš ï¸ Note: The `.exe` release represents the **production-ready build**,  
> while the source code here is **an experimental framework prototype**.
